#!/usr/bin/env python3.5

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

from __future__ import print_function

import os
import json
import pickle
import sys
import traceback
import pandas as pd
from sklearn.metrics import accuracy_score
import xgboost

# These are the paths to where SageMaker mounts interesting things in your container.

prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name='training'
training_path = os.path.join(input_path, channel_name)

class Logger:
	def __init__(self):
	    self.file = open(output_path + '/failure', 'w')

	def log(self, content):
		if isinstance(content,list):
			str_ = ""
			for ele in content:
				str_ += ele + '\n'
			content = str_	    

		self.file.write(content + '\n')
		self.file.flush()

# The function to execute the training.
def train():
	#elogger = Logger()
	#elogger.log('Starting the training.')
	try:

	    # Take the set of files and read them all into a single pandas dataframe
	    #input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]
	    #if len(input_files) == 0:
	    #    raise ValueError(('There are no files in {}.\n' +
	    #                      'This usually indicates that the channel ({}) was incorrectly specified,\n' +
	    #                      'the data specification in S3 was incorrectly specified or the role specified\n' +
	    #                      'does not have permission to access the data.').format(training_path, channel_name))
	   
	    #raw_data = [ pd.read_csv(file, header=None) for file in input_files ]
	    #train_data = pd.concat(raw_data)
	    train_data = pd.read_csv(training_path + "/" + "train.csv")
	    
	    with open(param_path) as json_file:
    		params= json.load(json_file)

	    max_depth_ = int(params['max_depth'])
	    lr_ = float(params['learning_rate'])
	    n_estimators_ = int(params['n_estimators'])
	    
	    #print(train_data.head())
	    # labels are in the first column
	    train_y = train_data.ix[:,0]
	    train_X = train_data.ix[:,1:]

	    # Now use scikit-learn's decision tree classifier to train the model.
	    clf = xgboost.XGBClassifier(
	        max_depth=max_depth_ , learning_rate=lr_,
	        n_estimators=n_estimators_, objective='binary:logistic'
	    )
	    clf = clf.fit(train_X, train_y)

	    test_data = pd.read_csv(training_path + "/" + "test.csv")
	    test_y = test_data.ix[:,0]
	    test_X = test_data.ix[:,1:]

	    y_pred = clf.predict(test_X)

	    print("acc: {}".format(accuracy_score(y_pred, test_y)),file=sys.stderr)
	    # save the model
	    with open(os.path.join(model_path, 'xgboost-model.pkl'), 'wb') as out:
	        pickle.dump(clf, out, protocol=0)

	except Exception as e:
	    # Write out an error file. This will be returned as the failureReason in the
	    # DescribeTrainingJob result.
	    trc = traceback.format_exc()
	    with open(os.path.join(output_path, 'failure'), 'w') as s:
	        s.write('Exception during training: ' + str(e) + '\n' + trc)
	    # Printing this causes the exception to be in the training job logs, as well.
	    print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
	    # A non-zero exit code causes the training job to be marked as Failed.
	    sys.exit(255)

if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
